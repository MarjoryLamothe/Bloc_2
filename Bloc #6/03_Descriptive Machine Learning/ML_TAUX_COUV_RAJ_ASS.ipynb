{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, OrdinalEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import Lasso, Ridge, LogisticRegression\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import r2_score, mean_absolute_percentage_error, accuracy_score, f1_score, ConfusionMatrixDisplay, RocCurveDisplay\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) # to avoid deprecation warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel(\"/Users/lamothemarjory/Downloads/Projet Full Stack/big_merge_V2_meteo.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_drop = [\"ETAGE\", \"ENDOMMAGEMENT\", \"NB_DEGAT_ARBRE\", 'PERF_CROI', 'SURF_TER_HA', 'DEGRAD_PPL', '25_GRID_PER', \n",
    "            'VOL_BOIS_MANQUANT', 'ACCR', 'UNIT_ACCR', 'UNIT_VOL_BOIS_MANQUANT']\n",
    "variables_to_keep = [col for col in data.columns if col not in to_drop]\n",
    "data = data.loc[:,variables_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = ['ALT', 'SLOPE25', 'AGE_PPL', 'DIV_STR_PPL', 'DDOM', 'DEG_SUR_PER', 'FEUILL_PER', 'CONIF_PER', 'SURF_TROU_AER', 'DBH', 'HAUTEUR_ARBRE', 'AGE_ARBRE',\n",
    "                    'PRCP_SUM', 'PRCP', 'PRCP_GROWTH', 'TAVE_AVG', 'TAVE', 'TAVE_GROWTH']\n",
    "categorical_features = ['LFI','ORIENTATION', 'RELIEF', 'PRODREG', 'PERI_CHENAUX', 'PERI_COULEES', 'PERI_AVALANCH', 'PERI_CHUTES',\n",
    "                        'MODE_REGEN', 'NIV_DEV', 'MELANGE', 'TYP_RAJ_PPL', 'ESPECE_DOM', 'FEU_RES', 'TYPE_FORET',\n",
    "                        'TRACES_FEU', 'INTENSITE_EXPLOIT', 'INT_IFN2_IFN3', 'INT_IFN3-IFN4']\n",
    "ordinal_categorical_features = ['HT_VEG', 'QUAL_STATION', 'REBOISEMENT_AN', 'TAILLE_PPL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_list = ['ALT', 'SLOPE25', 'AGE_PPL', 'DIV_STR_PPL', 'DDOM', 'DEG_SUR_PER', 'FEUILL_PER', 'CONIF_PER', 'SURF_TROU_AER', 'DBH', 'HAUTEUR_ARBRE', 'AGE_ARBRE',\n",
    "                'PRCP_SUM', 'PRCP', 'PRCP_GROWTH', 'TAVE_AVG', 'TAVE', 'TAVE_GROWTH',\n",
    "                \n",
    "                'HT_VEG', 'QUAL_STATION', 'REBOISEMENT_AN', 'TAILLE_PPL',\n",
    "\n",
    "                'LFI','ORIENTATION', 'RELIEF', 'PRODREG', 'PERI_CHENAUX', 'PERI_COULEES', 'PERI_AVALANCH', 'PERI_CHUTES',\n",
    "                'MODE_REGEN', 'NIV_DEV', 'MELANGE', 'TYP_RAJ_PPL', 'ESPECE_DOM', 'FEU_RES', 'TYPE_FORET',\n",
    "                'TRACES_FEU', 'INTENSITE_EXPLOIT', 'INT_IFN2_IFN3', 'INT_IFN3-IFN4']\n",
    "\n",
    "target_variable = 'TAUX_COUV_RAJ'\n",
    "\n",
    "X = data.drop(target_variable, axis = 1)\n",
    "Y = data.loc[:,target_variable]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=0, stratify = Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "categorical_transformer = Pipeline(\n",
    "    steps=[\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('encoder', OneHotEncoder(drop='first'))\n",
    "    ])\n",
    "\n",
    "ordinal_transformer = Pipeline(\n",
    "    steps=[\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('ordi_encoder', OrdinalEncoder(encoded_missing_value=0))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features),\n",
    "        ('ordi', ordinal_transformer, ordinal_categorical_features)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = preprocessor.fit_transform(X_train)\n",
    "X_test = preprocessor.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters :  {'alpha': 0.000538}\n",
      "Best R2 score :  0.7994220579111561\n"
     ]
    }
   ],
   "source": [
    "regressor = Lasso()\n",
    "params = {\n",
    "    'alpha': [0.000531, 0.000533, 0.000535, 0.000538, 0.00540]\n",
    "}\n",
    "gridsearch = GridSearchCV(regressor, param_grid = params, cv = 3)\n",
    "gridsearch.fit(X_train, Y_train)\n",
    "print(\"Best hyperparameters : \", gridsearch.best_params_)\n",
    "print(\"Best R2 score : \", gridsearch.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Lasso(alpha=0.00538)\n",
    "model.fit(X_train,Y_train)\n",
    "Y_train_pred = model.predict(X_train)\n",
    "Y_test_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score on training set :  0.7976407594109435\n",
      "R2 score on test set :  0.8044082000293653\n",
      "MAPE score on training set :  0.35182544103407776\n",
      "MAPE score on test set :  0.3422940041185154\n"
     ]
    }
   ],
   "source": [
    "print(\"R2 score on training set : \", model.score(X_train, Y_train))\n",
    "print(\"R2 score on test set : \", model.score(X_test, Y_test))\n",
    "print(\"MAPE score on training set : \", mean_absolute_percentage_error(Y_train, Y_train_pred))\n",
    "print(\"MAPE score on test set : \", mean_absolute_percentage_error(Y_test, Y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#column_names = []\n",
    "#for name, pipeline, features_list in preprocessor.transformers_:\n",
    "#    if name == 'num':\n",
    "#        features = features_list\n",
    "#    elif name == 'cat':\n",
    "#        features = pipeline.named_steps['encoder'].get_feature_names_out()\n",
    "#    else:\n",
    "#        features = pipeline.named_steps['ordi_encoder'].get_feature_names_out()\n",
    "#    column_names.extend(features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#coefs = pd.DataFrame(index = column_names, data = model.coef_.transpose(), columns=[\"coefficients\"])\n",
    "#coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature_importance = abs(coefs).sort_values(by = 'coefficients')\n",
    "#feature_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lamothemarjory/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "270 fits failed out of a total of 810.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "270 fits failed with the following error:\n",
      "joblib.externals.loky.process_executor._RemoteTraceback: \n",
      "\"\"\"\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/lamothemarjory/opt/anaconda3/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py\", line 436, in _process_worker\n",
      "    r = call_item()\n",
      "  File \"/Users/lamothemarjory/opt/anaconda3/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py\", line 288, in __call__\n",
      "    return self.fn(*self.args, **self.kwargs)\n",
      "  File \"/Users/lamothemarjory/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 595, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/Users/lamothemarjory/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 263, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/lamothemarjory/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 263, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/lamothemarjory/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 117, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/lamothemarjory/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 189, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/lamothemarjory/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 969, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/lamothemarjory/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 265, in fit\n",
      "    check_scalar(\n",
      "  File \"/Users/lamothemarjory/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\", line 1480, in check_scalar\n",
      "    raise ValueError(\n",
      "ValueError: min_samples_split == 1, must be >= 2.\n",
      "\"\"\"\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/lamothemarjory/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/lamothemarjory/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 476, in fit\n",
      "    trees = Parallel(\n",
      "  File \"/Users/lamothemarjory/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1061, in __call__\n",
      "    self.retrieve()\n",
      "  File \"/Users/lamothemarjory/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 938, in retrieve\n",
      "    self._output.extend(job.get(timeout=self.timeout))\n",
      "  File \"/Users/lamothemarjory/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 542, in wrap_future_result\n",
      "    return future.result(timeout=timeout)\n",
      "  File \"/Users/lamothemarjory/opt/anaconda3/lib/python3.8/concurrent/futures/_base.py\", line 444, in result\n",
      "    return self.__get_result()\n",
      "  File \"/Users/lamothemarjory/opt/anaconda3/lib/python3.8/concurrent/futures/_base.py\", line 389, in __get_result\n",
      "    raise self._exception\n",
      "ValueError: min_samples_split == 1, must be >= 2.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/lamothemarjory/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:953: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
      " 0.58655222 0.58590194 0.58941345 0.59474574 0.58876317 0.59123423\n",
      " 0.59227468 0.58941345 0.5916244  0.59071401 0.58616205 0.5916244\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.58915334 0.58915334 0.59630641 0.58915334 0.59123423 0.59253479\n",
      " 0.58772272 0.59175445 0.59227468 0.59253479 0.59305501 0.59253479\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.58798283 0.58525166 0.58928339 0.58707244 0.58811289 0.59032384\n",
      " 0.58850306 0.58993367 0.5872025  0.58525166 0.58681233 0.58681233\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.59188451 0.5960463  0.59214462 0.59058395 0.59630641 0.59071401\n",
      " 0.59149434 0.59110417 0.59149434 0.5927949  0.59240473 0.59344518\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.60124854 0.59136429 0.59760697 0.59383535 0.59149434 0.59266485\n",
      " 0.59617636 0.59058395 0.58993367 0.59435557 0.5960463  0.59253479\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.58486149 0.59422552 0.58902328 0.59097412 0.58772272 0.59227468\n",
      " 0.58889322 0.5851216  0.58980362 0.59110417 0.59071401 0.59136429\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.59656652 0.59253479 0.59799714 0.59695669 0.59578619 0.59526596\n",
      " 0.59266485 0.59708675 0.59188451 0.59331513 0.59500585 0.59500585\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.59552608 0.59422552 0.59227468 0.59786708 0.59370529 0.59773703\n",
      " 0.59422552 0.59266485 0.59461568 0.59682664 0.60020809 0.59695669\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.58785278 0.58694239 0.59097412 0.59032384 0.5927949  0.59006373\n",
      " 0.58915334 0.59448563 0.59097412 0.59318507 0.58902328 0.59175445\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.59539602 0.59266485 0.60020809 0.60059826 0.59916764 0.59630641\n",
      " 0.58772272 0.59448563 0.59513591 0.59513591 0.59474574 0.5948758\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.59565613 0.59981792 0.59747692 0.5992977  0.59812719 0.59578619\n",
      " 0.59266485 0.59578619 0.59461568 0.59695669 0.59266485 0.59513591\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.58980362 0.59123423 0.59266485 0.59292496 0.59240473 0.58967356\n",
      " 0.59032384 0.58928339 0.58980362 0.59526596 0.59032384 0.59097412\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.59578619 0.59565613 0.5992977  0.59370529 0.59942775 0.59812719\n",
      " 0.59747692 0.60554038 0.59851736 0.60007803 0.59838731 0.59903759\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.5972168  0.59500585 0.59877747 0.60059826 0.59760697 0.59708675\n",
      " 0.59669658 0.59695669 0.59656652 0.60072831 0.60137859 0.59877747\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.59448563 0.59578619 0.59331513 0.59227468 0.59825725 0.59227468\n",
      " 0.59084406 0.59500585 0.59500585 0.59149434 0.59149434 0.5960463 ]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters :  {'max_depth': 13, 'min_samples_leaf': 1, 'min_samples_split': 3, 'n_estimators': 100}\n",
      "Best validation accuracy :  0.6055403823644167\n"
     ]
    }
   ],
   "source": [
    "classifier = RandomForestClassifier(n_jobs=4)\n",
    "\n",
    "params = {\n",
    "    'max_depth': [9, 10, 11, 12, 13],\n",
    "    'min_samples_leaf': [1, 2, 5],\n",
    "    'min_samples_split': [1, 2, 3],\n",
    "    'n_estimators': [90, 100, 110, 120, 130, 140]\n",
    "}\n",
    "model2 = GridSearchCV(classifier, param_grid = params, cv = 3)\n",
    "model2.fit(X_train, Y_train)\n",
    "\n",
    "print(\"Best hyperparameters : \", model2.best_params_)\n",
    "print(\"Best validation accuracy : \", model2.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_pred2 = model2.predict(X_train)\n",
    "Y_train_proba2 = model2.predict_proba(X_train)\n",
    "Y_test_pred2 = model2.predict(X_test)\n",
    "Y_test_proba2 = model2.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on training set :  0.94914813369749\n",
      "accuracy on test set :  0.6068642745709828\n",
      "\n",
      "f1-score on training set :  0.9487866555268218\n",
      "f1-score on test set :  0.5807057713339199\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy on training set : \", accuracy_score(Y_train, Y_train_pred2))\n",
    "print(\"accuracy on test set : \", accuracy_score(Y_test, Y_test_pred2))\n",
    "print()\n",
    "\n",
    "print(\"f1-score on training set : \", f1_score(Y_train, Y_train_pred2, average='weighted'))\n",
    "print(\"f1-score on test set : \", f1_score(Y_test, Y_test_pred2, average='weighted'))\n",
    "print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1030ce3dcf70cffae378a5b7d99d51872265078c65f54565d4bc0d50aa55751f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
